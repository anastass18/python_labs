## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 7

### A. –¢–µ—Å—Ç—ã –¥–ª—è src/lib/text.py

``` python
import unittest
import pytest
import sys
import os

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) # –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ –ø—É—Ç—å Python

from scr.lib.text import normalize, tokenize, count_freq, top_n # –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏


class TestText:
    @pytest.mark.parametrize(
        "input_text, expected",
        [
            ("Hello world", "hello world"),
            (" PYTHON  Programming  ", "python programming"),
            ("Test123", "test123"),
            ("", ""),
            ("  ", ""),
            ("Hello!!??", "hello!!??"),
            ("–ü—Ä–∏–≤–µ—Ç –ú–∏—Ä", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
            ("caf√©", "caf√©"),
        ],
    )
    def test_normalize(self, input_text, expected):
        assert normalize(input_text) == expected

    @pytest.mark.parametrize(
        "input_text, expected",
        [
            ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
            ("hello,world!!!", ["hello", "world"]),
            ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
            ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
            ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
            ("", []),  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
            ("   ", []),  # —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã
            ("!!!@@@###", []),  # —Ç–æ–ª—å–∫–æ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
            ("—Ä–∞–∑ –¥–≤–∞.—Ç—Ä–∏,—á–µ—Ç—ã—Ä–µ!–ø—è—Ç—å?", ["—Ä–∞–∑", "–¥–≤–∞", "—Ç—Ä–∏", "—á–µ—Ç—ã—Ä–µ", "–ø—è—Ç—å"]),
            ("—Ü–∏—Ñ—Ä—ã123 –∏ —Å–∏–º–≤–æ–ª—ã!", ["—Ü–∏—Ñ—Ä—ã123", "–∏", "—Å–∏–º–≤–æ–ª—ã"]),
            ("'–∫–∞–≤—ã—á–∫–∏' \"–¥–≤–æ–π–Ω—ã–µ\"", ["–∫–∞–≤—ã—á–∫–∏", "–¥–≤–æ–π–Ω—ã–µ"]),
        ],
    )
    def test_tokenize(self, input_text, expected):
        assert tokenize(input_text) == expected

    @pytest.mark.parametrize(
        "tokens, expected",
        [
            (["hello", "world", "hello"], {"hello": 2, "world": 1}),
            (["a", "b", "a", "c", "c"], {"a": 2, "b": 1, "c": 2}),
            ([], {}),  # –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
            (["x"], {"x": 1}),  # –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç
            (["a", "a", "a"], {"a": 3}),  # –≤—Å–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
            (["1", "2", "3"], {"1": 1, "2": 1, "3": 1}),  # –≤—Å–µ —Ä–∞–∑–Ω—ã–µ
        ],
    )
    def test_count_freq(self, tokens, expected):
        assert count_freq(tokens) == expected

    @pytest.mark.parametrize(
        "freq, n, expected",
        [
            ({"hello": 2, "world": 1}, 1, [("hello", 2)]),
            ({"a": 5, "b": 5, "c": 3}, 2, [("a", 5), ("b", 5)]),  # –Ω–∏—á—å—è
            ({"x": 1}, 1, [("x", 1)]),  # –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç
            ({}, 5, []),  # –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
            ({"a": 10, "b": 10, "c": 10}, 2, [("a", 10), ("b", 10)]),  # –≤—Å–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
            ({"z": 1, "y": 2, "x": 3}, 2, [("x", 3), ("y", 2)]),  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä—è–¥–∫–∞
        ],
    )
    def test_top_n(self, freq, n, expected):
        assert top_n(freq, n) == expected
```

![test_text!](/images/lab7/test_text.png) 

![test_text2!](/images/lab7/test_text2.png)

### B. –¢–µ—Å—Ç—ã –¥–ª—è src/lab05/json_csv.py

``` python
import pytest
import csv, json
from pathlib import Path
from scr.lab5.json_csv import json_to_csv, csv_to_json


def test_json_to_csv_roundtrip(tmp_path: Path):
    scr = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = [
        {"name": "Alice", "age": 22},
        {"name": "Bob", "age": 25},
    ]
    scr.write_text(json.dumps(data, ensure_ascii = False, indent = 2), encoding = "utf-8")
    json_to_csv(str(scr), str(dst))
    with dst.open(encoding = "utf-8") as f:
        rows = list(csv.DictReader(f))
    assert len(rows) == 2
    assert {"name", "age"} <= set(rows[0].keys())


def test_csv_to_json_roundtrip(tmp_path: Path):
    scr = tmp_path / "people.csv"
    dst = tmp_path / "people.json"
    data = [
        {"name": "Alice", "age": "22"},
        {"name": "Bob", "age": "25"},
    ]
    with open(scr, "w", newline = "", encoding = "utf-8") as f:
        fieldnames = list(data[0].keys())
        writer = csv.DictWriter(f, fieldnames = fieldnames)
        writer.writeheader()
        writer.writerows(data)
    csv_to_json(str(scr), str(dst))
    with dst.open(encoding = "utf-8") as f:
        rows = json.load(f)
    assert len(rows) == 2


@pytest.mark.parametrize(
    "function, input_file, error",
    [
        (json_to_csv, "people.json", ValueError),
    ],
)
def test_json_to_csv(function, input_file, error, tmp_path: Path):
    file_path = tmp_path / input_file
    file_path.write_text("Error???", encoding = "utf-8")
    dst = tmp_path / "people.csv"
    f = json_to_csv if function is json_to_csv else csv_to_json
    with pytest.raises(error):
        f(str(file_path), str(dst))
```

![json_csv_test!](/images/lab7/json_csv_test.png)

### C. –°—Ç–∏–ª—å –∫–æ–¥–∞ (```black```)

![black!](/images/lab7/black.png)
