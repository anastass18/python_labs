import unittest
import pytest
import sys
import os

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) # –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ –ø—É—Ç—å Python

from scr.lib.text import normalize, tokenize, count_freq, top_n # –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏


class TestText:
    @pytest.mark.parametrize(
        "input_text, expected",
        [
            ("Hello world", "hello world"),
            (" PYTHON  Programming  ", "python programming"),
            ("Test123", "test123"),
            ("", ""),
            ("  ", ""),
            ("Hello!!??", "hello!!??"),
            ("–ü—Ä–∏–≤–µ—Ç –ú–∏—Ä", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
            ("caf√©", "caf√©"),
        ],
    )
    def test_normalize(self, input_text, expected):
        assert normalize(input_text) == expected

    @pytest.mark.parametrize(
        "input_text, expected",
        [
            ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
            ("hello,world!!!", ["hello", "world"]),
            ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
            ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
            ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
            ("", []),  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
            ("   ", []),  # —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã
            ("!!!@@@###", []),  # —Ç–æ–ª—å–∫–æ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
            ("—Ä–∞–∑ –¥–≤–∞.—Ç—Ä–∏,—á–µ—Ç—ã—Ä–µ!–ø—è—Ç—å?", ["—Ä–∞–∑", "–¥–≤–∞", "—Ç—Ä–∏", "—á–µ—Ç—ã—Ä–µ", "–ø—è—Ç—å"]),
            ("—Ü–∏—Ñ—Ä—ã123 –∏ —Å–∏–º–≤–æ–ª—ã!", ["—Ü–∏—Ñ—Ä—ã123", "–∏", "—Å–∏–º–≤–æ–ª—ã"]),
            ("'–∫–∞–≤—ã—á–∫–∏' \"–¥–≤–æ–π–Ω—ã–µ\"", ["–∫–∞–≤—ã—á–∫–∏", "–¥–≤–æ–π–Ω—ã–µ"]),
        ],
    )
    def test_tokenize(self, input_text, expected):
        assert tokenize(input_text) == expected

    @pytest.mark.parametrize(
        "tokens, expected",
        [
            (["hello", "world", "hello"], {"hello": 2, "world": 1}),
            (["a", "b", "a", "c", "c"], {"a": 2, "b": 1, "c": 2}),
            ([], {}),  # –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
            (["x"], {"x": 1}),  # –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç
            (["a", "a", "a"], {"a": 3}),  # –≤—Å–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
            (["1", "2", "3"], {"1": 1, "2": 1, "3": 1}),  # –≤—Å–µ —Ä–∞–∑–Ω—ã–µ
        ],
    )
    def test_count_freq(self, tokens, expected):
        assert count_freq(tokens) == expected

    @pytest.mark.parametrize(
        "freq, n, expected",
        [
            ({"hello": 2, "world": 1}, 1, [("hello", 2)]),
            ({"a": 5, "b": 5, "c": 3}, 2, [("a", 5), ("b", 5)]),  # –Ω–∏—á—å—è
            ({"x": 1}, 1, [("x", 1)]),  # –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç
            ({}, 5, []),  # –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
            ({"a": 10, "b": 10, "c": 10}, 2, [("a", 10), ("b", 10)]),  # –≤—Å–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
            ({"z": 1, "y": 2, "x": 3}, 2, [("x", 3), ("y", 2)]),  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä—è–¥–∫–∞
        ],
    )
    def test_top_n(self, freq, n, expected):
        assert top_n(freq, n) == expected
